{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "\n",
    "<br><br><h1>Example of using TensorFlow to build a Classifier for Iris Data</h1>\n",
    "<img src=\"images/Iris-Example-1.png\">\n",
    "<img src=\"images/Iris-Example-2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "<h2>Example of a Deep Neural Network (DNN) to classify Iris Petals into three Classes [0,1,2] </h2>\n",
    "<h3> The code below is adapted from the TensorFlow example, with modifications </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "def iris_classifier_dnn(hidden_units=None, training_steps=2000, \n",
    "                    model_dir=\"/tmp/iris_model\",\n",
    "                    delete_old_model=False\n",
    "                   ):\n",
    "    \n",
    "  # Set the model type to be SVM-{kernel}\n",
    "  modelType = \"DNN\"\n",
    "    \n",
    "  # 0 represents setosa 1 represents versicolor 2 represents virginica\n",
    "  iris_classes = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "    \n",
    "  # If the training and test sets aren't stored locally, download them.\n",
    "  if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if not os.path.exists(IRIS_TEST):\n",
    "    raw = urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if delete_old_model:\n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "        print(\"Deleting old model {0}\\n\" .format(model_dir))\n",
    "  # Load datasets.\n",
    "  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TRAINING,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TEST,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "\n",
    "  # Specify that all features have real-value data\n",
    "  feature_columns = [tf.feature_column.numeric_column(\"x\", \n",
    "                                                      shape=[training_set.data.shape[1]])]\n",
    "\n",
    "  print(\"Featured Columns {0}\\n\" .format(feature_columns))                                                    \n",
    "  # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "  print(\"Building DNN with {0} hidden units\\n\" .format(hidden_units))\n",
    "  classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                          hidden_units=hidden_units,\n",
    "                                          n_classes=3,\n",
    "                                          model_dir=\"/tmp/iris_model\")\n",
    "  # Define the training inputs\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(training_set.data)},\n",
    "      y=np.array(training_set.target),\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "\n",
    "  # Train model.\n",
    "  classifier.train(input_fn=train_input_fn, steps=training_steps)\n",
    "\n",
    "  # Define the test inputs\n",
    "  test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(test_set.data)},\n",
    "      y=np.array(test_set.target),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "  # Evaluate accuracy.\n",
    "  accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "  print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "  # Classify two new flower samples.\n",
    "  new_samples = np.array(\n",
    "      [[6.4, 3.2, 4.5, 1.5],\n",
    "       [5.8, 3.1, 5.0, 1.7],\n",
    "       [6.4 ,2.8, 5.6 ,2.2],\n",
    "       [5.0 , 2.3 ,3.3 ,1.0 ],\n",
    "       [4.9 ,2.5 ,4.5 ,1.7 ],\n",
    "       [4.9 ,3.1 ,1.5 ,0.1 ],\n",
    "       [5.7,3.8 ,1.7 ,0.3]], dtype=np.float32)\n",
    "    \n",
    "     \n",
    "  predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": new_samples},\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "  predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "  \n",
    "  predicted_classes = [p[\"class_ids\"] for p in predictions]\n",
    "  # Store probabilities for each prediction  \n",
    "  probs = [p[\"probabilities\"] for p in predictions]\n",
    "  probabilities = []\n",
    "  predicted_class_names = []\n",
    "  for i in range(len(predicted_classes)):\n",
    "    predicted_classes[i] = int(predicted_classes[i])\n",
    "    predicted_class_names.append(iris_classes[int(predicted_classes[i])])\n",
    "    pr = probs[i]\n",
    "    probabilities.append(pr[int(predicted_classes[i])]*100.0)\n",
    "\n",
    "  print(\n",
    "      \"New Samples, Class Predictions:    {}\\n\"\n",
    "      .format(predicted_classes))\n",
    "  result= {\"training-size\" :  training_set.data.shape,\n",
    "           \"test-size\" : test_set.data.shape,\n",
    "           \"train-steps\" : training_steps,\n",
    "           \"model_dir\"  : model_dir,\n",
    "           \"model-type\" : modelType,\n",
    "           \"hidden-units\" : str(hidden_units),\n",
    "           \"accuracy\" : accuracy_score, \n",
    "           \"prediction\": predicted_classes,\n",
    "           \"prediction-names\": predicted_class_names,\n",
    "           \"probabilities\" : probabilities}\n",
    "\n",
    "  return result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "<h2> Run the Code above and Below: This will create a DNN and run predictions on the Iris model data</h2>\n",
    "    <ul><li> You can play with the hidden_units and training steps to see if this makes a difference to accuracy and predictions\n",
    "    </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version {0}\\n\" .format(tf.__version__))\n",
    "hidden_units = [10 , 20 , 10]\n",
    "training_steps = 2000\n",
    "model_dir = \"/tmp/iris_model\"\n",
    "delete_old_model= True\n",
    "result = iris_classifier_dnn(hidden_units=hidden_units, \n",
    "                         training_steps=training_steps, \n",
    "                         model_dir=model_dir,\n",
    "                        delete_old_model=delete_old_model)\n",
    "print(\"Result: {0}\\n\" .format(result))\n",
    "print(\"Expected Results: [1, 2, 2, 1, 2, 0, 0]\\n\")\n",
    "print(\"Expected Results: ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "<ul>\n",
    "<li>You should get an accuracy of 96.6 in the above DNN for Iris </li>\n",
    "<li> You should get the following predictions:  [1, 2, 2, 1, 2, 0, 0]</li>\n",
    "<li>You should get the follwing predictions: ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']</li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "\n",
    "<h1> Example Of SVM for the Same Iris Classification</h1>\n",
    "<ul>\n",
    "<li> Modify the code below, and add other SVM kernels, such as \"poly\", \"sigmoid\" , \"linear\" and \"rbf\"</li>\n",
    "<li> Modify the function iris_classifier_svm(kernel=\"poly\") to take in a parameter for kernel='all'\n",
    "<li> The function should return a JSON compaitable object (dictionary) that contains the results generated by each classifier\n",
    "<li> Print out results from 'all' SVM kernels for the iris example, and print their predictions for each kernel</li>\n",
    "<li> Add a decisionTree classified to the mix, and print out its prediction with the above 4  SVM kernels</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from six.moves.urllib.request import urlopen\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "label_name = 'Species'\n",
    "\n",
    "def iris_classifier_svm(kernel='rbf',\n",
    "                    model_dir=\"/tmp/iris_model\",\n",
    "                    delete_old_model=False\n",
    "                   ):\n",
    "    \n",
    "  # Set the model type to be SVM-{kernel}\n",
    "  modelType = \"SVM-\" + kernel\n",
    "  # 0 represents setosa 1 represents versicolor 2 represents virginica\n",
    "  iris_classes = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "    \n",
    "  # If the training and test sets aren't stored locally, download them.\n",
    "  if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if not os.path.exists(IRIS_TEST):\n",
    "    raw = urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if delete_old_model:\n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "        print(\"Deleting old model {0}\\n\" .format(model_dir))\n",
    "  # Load datasets.\n",
    "  # Parse the local CSV file.\n",
    "  training_df = pd.read_csv(filepath_or_buffer=IRIS_TRAINING,\n",
    "                                names=CSV_COLUMN_NAMES,  # list of column names\n",
    "                                header=0  # ignore the first row of the CSV file.\n",
    "                               )\n",
    "    # train now holds a pandas DataFrame, which is data structure\n",
    "    # analogous to a table.\n",
    "\n",
    "    # 1. Assign the DataFrame's labels (the right-most column) to train_label.\n",
    "    # 2. Delete (pop) the labels from the DataFrame.\n",
    "    # 3. Assign the remainder of the DataFrame to train_features\n",
    "  train_features, train_label = training_df, training_df.pop(label_name)\n",
    "\n",
    "  \n",
    "  # Apply the preceding logic to the test set.\n",
    "  \n",
    "  test_df = pd.read_csv(IRIS_TEST, names=CSV_COLUMN_NAMES, header=0)\n",
    "  test_features, test_label = test_df, test_df.pop(label_name)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "  # Build SVM\n",
    "  print(\"Building SVM using a {0} Kernel\\n\" .format(kernel))\n",
    "\n",
    "  classifier = svm.SVC(decision_function_shape='ovo',kernel=kernel,  probability=True)\n",
    "  \n",
    "\n",
    "  \n",
    "  # Train model.\n",
    "  classifier.fit(train_features.values, train_label.values)\n",
    "\n",
    " \n",
    "\n",
    "  # Evaluate accuracy.\n",
    "  accuracy_score = classifier.score(train_features.values, train_label.values)\n",
    "\n",
    "  print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "  # Classify two new flower samples.\n",
    "  # Classify two new flower samples.\n",
    "  new_samples = np.array(\n",
    "      [[6.4, 3.2, 4.5, 1.5],\n",
    "       [5.8, 3.1, 5.0, 1.7],\n",
    "       [6.4 ,2.8, 5.6 ,2.2],\n",
    "       [5.0 , 2.3 ,3.3 ,1.0 ],\n",
    "       [4.9 ,2.5 ,4.5 ,1.7 ],\n",
    "       [4.9 ,3.1 ,1.5 ,0.1 ],\n",
    "       [5.7,3.8 ,1.7 ,0.3]], dtype=np.float32)\n",
    "\n",
    " \n",
    "\n",
    "  predicted_classes = classifier.predict(new_samples)\n",
    "  probabilities = classifier.predict_log_proba(new_samples)\n",
    "  predicted_class_names = []\n",
    "  for i in range(len(predicted_classes)):\n",
    "    predicted_class_names.append(iris_classes[int(predicted_classes[i])])\n",
    "  \n",
    "  #for i in range(len(predicted_classes)):\n",
    "  #  predicted_classes[i] = int(predicted_classes[i])\n",
    "  print(\n",
    "      \"New Samples, Class Predictions:    {}\\n\"\n",
    "      .format(predicted_classes))\n",
    "  print(\n",
    "      \"New Samples, Class Prediction Names:    {}\\n\"\n",
    "      .format(predicted_class_names))\n",
    "  result= {\"training-size\" :  train_features.shape,\n",
    "           \"test-size\" : test_features.shape,\n",
    "           \"Model-type\" : modelType,\n",
    "           \"model_dir\"  : model_dir,\n",
    "           \"accuracy\" : accuracy_score, \n",
    "           \"prediction\": predicted_classes,\n",
    "           \"prediction-names\": predicted_class_names}\n",
    "\n",
    "  return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class SVM\n",
    "# Other kernels = must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, \n",
    "kernel = \"rbf\"   \n",
    "iris_classifier_svm(kernel=kernel)\n",
    "\n",
    "## Modify code above to take in a parameter for kernel='all'\n",
    "## Print predictions from each SVM kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<li> You should get the following predictions:  [1, 2, 2, 1, 2, 0, 0]</li>\n",
    "<li>You should get the follwing predictions: ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']</li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "<h2> Combine SVM and DNN iris_classifiers into a single wrapper and print all predictions </h2>\n",
    "<ul>\n",
    "<li> Write a  function called iris_clasifier() that calls <em>iris_classifier_svm(kernel=\"all\")<em> and <em>iris_classifier_dnn(..)</em></li>\n",
    "<li> The function should return a JSON compaitable object (dictionary) that contains all the results from each classifier\n",
    "<li> Print the Results object: Predictions from all SMV kernels, DecisionTree and DNN </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
