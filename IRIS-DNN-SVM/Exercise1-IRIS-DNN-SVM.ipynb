{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "\n",
    "<br><br><h1>Example of using TensorFlow to build a Classifier for Iris Data</h1>\n",
    "<img src=\"images/Iris-Example-1.png\">\n",
    "<img src=\"images/Iris-Example-2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "<h2>Example of a Deep Neural Network (DNN) to classify Iris Petals into three Classes [0,1,2] </h2>\n",
    "<h3> The code below is adapted from the TensorFlow example, with modifications </h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "def iris_classifier_dnn(hidden_units=None, training_steps=2000, \n",
    "                    model_dir=\"/tmp/iris_model\",\n",
    "                    delete_old_model=False\n",
    "                   ):\n",
    "    \n",
    "  # Set the model type to be SVM-{kernel}\n",
    "  modelType = \"DNN\"\n",
    "    \n",
    "  # 0 represents setosa 1 represents versicolor 2 represents virginica\n",
    "  iris_classes = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "    \n",
    "  # If the training and test sets aren't stored locally, download them.\n",
    "  if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if not os.path.exists(IRIS_TEST):\n",
    "    raw = urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if delete_old_model:\n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "        print(\"Deleting old model {0}\\n\" .format(model_dir))\n",
    "  # Load datasets.\n",
    "  training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TRAINING,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "  test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "      filename=IRIS_TEST,\n",
    "      target_dtype=np.int,\n",
    "      features_dtype=np.float32)\n",
    "\n",
    "  # Specify that all features have real-value data\n",
    "  feature_columns = [tf.feature_column.numeric_column(\"x\", \n",
    "                                                      shape=[training_set.data.shape[1]])]\n",
    "\n",
    "  print(\"Featured Columns {0}\\n\" .format(feature_columns))                                                    \n",
    "  # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "  print(\"Building DNN with {0} hidden units\\n\" .format(hidden_units))\n",
    "  classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                          hidden_units=hidden_units,\n",
    "                                          n_classes=3,\n",
    "                                          model_dir=\"/tmp/iris_model\")\n",
    "  # Define the training inputs\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(training_set.data)},\n",
    "      y=np.array(training_set.target),\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "\n",
    "  # Train model.\n",
    "  classifier.train(input_fn=train_input_fn, steps=training_steps)\n",
    "\n",
    "  # Define the test inputs\n",
    "  test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": np.array(test_set.data)},\n",
    "      y=np.array(test_set.target),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "  # Evaluate accuracy.\n",
    "  accuracy_score = classifier.evaluate(input_fn=test_input_fn)[\"accuracy\"]\n",
    "\n",
    "  print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "  # Classify two new flower samples.\n",
    "  new_samples = np.array(\n",
    "      [[6.4, 3.2, 4.5, 1.5],\n",
    "       [5.8, 3.1, 5.0, 1.7],\n",
    "       [6.4 ,2.8, 5.6 ,2.2],\n",
    "       [5.0 , 2.3 ,3.3 ,1.0 ],\n",
    "       [4.9 ,2.5 ,4.5 ,1.7 ],\n",
    "       [4.9 ,3.1 ,1.5 ,0.1 ],\n",
    "       [5.7,3.8 ,1.7 ,0.3]], dtype=np.float32)\n",
    "    \n",
    "     \n",
    "  predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": new_samples},\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "\n",
    "  predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "  \n",
    "  predicted_classes = [p[\"class_ids\"] for p in predictions]\n",
    "  # Store probabilities for each prediction  \n",
    "  probs = [p[\"probabilities\"] for p in predictions]\n",
    "  probabilities = []\n",
    "  predicted_class_names = []\n",
    "  for i in range(len(predicted_classes)):\n",
    "    predicted_classes[i] = int(predicted_classes[i])\n",
    "    predicted_class_names.append(iris_classes[int(predicted_classes[i])])\n",
    "    pr = probs[i]\n",
    "    probabilities.append(pr[int(predicted_classes[i])]*100.0)\n",
    "\n",
    "  print(\n",
    "      \"New Samples, Class Predictions:    {}\\n\"\n",
    "      .format(predicted_classes))\n",
    "  result= {\"training-size\" :  training_set.data.shape,\n",
    "           \"test-size\" : test_set.data.shape,\n",
    "           \"train-steps\" : training_steps,\n",
    "           \"model_dir\"  : model_dir,\n",
    "           \"model-type\" : modelType,\n",
    "           \"hidden-units\" : str(hidden_units),\n",
    "           \"accuracy\" : accuracy_score, \n",
    "           \"prediction\": predicted_classes,\n",
    "           \"prediction-names\": predicted_class_names,\n",
    "           \"probabilities\" : probabilities}\n",
    "\n",
    "  return result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "<h2> Run the Code above and Below: This will create a DNN and run predictions on the Iris model data</h2>\n",
    "    <ul><li> You can play with the hidden_units and training steps to see if this makes a difference to accuracy and predictions\n",
    "    </li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 1.3.0\n",
      "\n",
      "Deleting old model /tmp/iris_model\n",
      "\n",
      "Featured Columns [_NumericColumn(key='x', shape=(4,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "\n",
      "Building DNN with [10, 30, 10] hidden units\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_tf_random_seed': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_model_dir': '/tmp/iris_model', '_log_step_count_steps': 100, '_session_config': None}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 307.948, step = 1\n",
      "INFO:tensorflow:global_step/sec: 814.95\n",
      "INFO:tensorflow:loss = 20.1675, step = 101 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 839.017\n",
      "INFO:tensorflow:loss = 9.77627, step = 201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 806.892\n",
      "INFO:tensorflow:loss = 12.2683, step = 301 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 838.868\n",
      "INFO:tensorflow:loss = 8.45627, step = 401 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.556\n",
      "INFO:tensorflow:loss = 21.4563, step = 501 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 824.412\n",
      "INFO:tensorflow:loss = 11.7478, step = 601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.052\n",
      "INFO:tensorflow:loss = 11.0096, step = 701 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 880.531\n",
      "INFO:tensorflow:loss = 5.25654, step = 801 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 864.858\n",
      "INFO:tensorflow:loss = 3.05667, step = 901 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 841.817\n",
      "INFO:tensorflow:loss = 4.76032, step = 1001 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 835.455\n",
      "INFO:tensorflow:loss = 13.3801, step = 1101 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.828\n",
      "INFO:tensorflow:loss = 11.1625, step = 1201 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 852.295\n",
      "INFO:tensorflow:loss = 9.5361, step = 1301 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 831.171\n",
      "INFO:tensorflow:loss = 4.91319, step = 1401 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.111\n",
      "INFO:tensorflow:loss = 3.10998, step = 1501 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 850.549\n",
      "INFO:tensorflow:loss = 6.90044, step = 1601 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 864.05\n",
      "INFO:tensorflow:loss = 5.69742, step = 1701 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 818.466\n",
      "INFO:tensorflow:loss = 12.2282, step = 1801 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 842.182\n",
      "INFO:tensorflow:loss = 7.05295, step = 1901 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 817.724\n",
      "INFO:tensorflow:loss = 7.51846, step = 2001 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 802.248\n",
      "INFO:tensorflow:loss = 5.50152, step = 2101 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 833.99\n",
      "INFO:tensorflow:loss = 6.35155, step = 2201 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.726\n",
      "INFO:tensorflow:loss = 10.6389, step = 2301 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 854.235\n",
      "INFO:tensorflow:loss = 2.75188, step = 2401 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 811.538\n",
      "INFO:tensorflow:loss = 1.67039, step = 2501 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 831.281\n",
      "INFO:tensorflow:loss = 10.3763, step = 2601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 826.111\n",
      "INFO:tensorflow:loss = 11.9559, step = 2701 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 832.046\n",
      "INFO:tensorflow:loss = 9.38388, step = 2801 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 822.587\n",
      "INFO:tensorflow:loss = 5.67132, step = 2901 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 808.492\n",
      "INFO:tensorflow:loss = 7.43904, step = 3001 (0.124 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.688\n",
      "INFO:tensorflow:loss = 6.60916, step = 3101 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 817.852\n",
      "INFO:tensorflow:loss = 8.14018, step = 3201 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.261\n",
      "INFO:tensorflow:loss = 9.72542, step = 3301 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 841.132\n",
      "INFO:tensorflow:loss = 4.50017, step = 3401 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 852.457\n",
      "INFO:tensorflow:loss = 2.41342, step = 3501 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 851.032\n",
      "INFO:tensorflow:loss = 9.18219, step = 3601 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 838.644\n",
      "INFO:tensorflow:loss = 5.54573, step = 3701 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 837.477\n",
      "INFO:tensorflow:loss = 12.0299, step = 3801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.276\n",
      "INFO:tensorflow:loss = 1.97804, step = 3901 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 827.7\n",
      "INFO:tensorflow:loss = 6.20923, step = 4001 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 837.728\n",
      "INFO:tensorflow:loss = 5.10362, step = 4101 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.77\n",
      "INFO:tensorflow:loss = 3.2605, step = 4201 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 740.302\n",
      "INFO:tensorflow:loss = 2.62431, step = 4301 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 862.458\n",
      "INFO:tensorflow:loss = 2.53673, step = 4401 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.549\n",
      "INFO:tensorflow:loss = 8.29795, step = 4501 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 820.212\n",
      "INFO:tensorflow:loss = 5.22555, step = 4601 (0.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 754.586\n",
      "INFO:tensorflow:loss = 4.07201, step = 4701 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 795.542\n",
      "INFO:tensorflow:loss = 12.1887, step = 4801 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 890.389\n",
      "INFO:tensorflow:loss = 4.3911, step = 4901 (0.112 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.06634.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-25-10:35:24\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-25-10:35:24\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.966667, average_loss = 0.0622638, global_step = 5000, loss = 1.86791\n",
      "\n",
      "Test Accuracy: 0.966667\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-5000\n",
      "New Samples, Class Predictions:    [1, 2, 2, 1, 2, 0, 0]\n",
      "\n",
      "Result: {'model_dir': '/tmp/iris_model', 'test-size': (30, 4), 'probabilities': [99.989831447601318, 76.146531105041504, 99.976509809494019, 99.865388870239258, 99.187743663787842, 99.987530708312988, 99.989604949951172], 'prediction-names': ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa'], 'prediction': [1, 2, 2, 1, 2, 0, 0], 'model-type': 'DNN', 'hidden-units': '[10, 30, 10]', 'accuracy': 0.96666664, 'training-size': (120, 4), 'train-steps': 5000}\n",
      "\n",
      "Expected Results: [1, 2, 2, 1, 2, 0, 0]\n",
      "\n",
      "Expected Results: ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version {0}\\n\" .format(tf.__version__))\n",
    "hidden_units = [10 , 30, 10]\n",
    "training_steps = 5000\n",
    "model_dir = \"/tmp/iris_model\"\n",
    "delete_old_model= True\n",
    "result = iris_classifier_dnn(hidden_units=hidden_units, \n",
    "                         training_steps=training_steps, \n",
    "                         model_dir=model_dir,\n",
    "                        delete_old_model=delete_old_model)\n",
    "print(\"Result: {0}\\n\" .format(result))\n",
    "print(\"Expected Results: [1, 2, 2, 1, 2, 0, 0]\\n\")\n",
    "print(\"Expected Results: ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "<ul>\n",
    "<li>You should get an accuracy of 96.6 in the above DNN for Iris </li>\n",
    "<li> You should get the following predictions:  [1, 2, 2, 1, 2, 0, 0]</li>\n",
    "<li>You should get the follwing predictions: ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']</li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "\n",
    "<h1> Example Of SVM for the Same Iris Classification</h1>\n",
    "<ul>\n",
    "<li> Modify the code below, and add other SVM kernels, such as \"poly\", \"sigmoid\" , \"linear\" and \"rbf\"</li>\n",
    "<li> Modify the function iris_classifier_svm(kernel=\"poly\") to take in a parameter for kernel='all'\n",
    "<li> The function should return a JSON compaitable object (dictionary) that contains the results generated by each classifier\n",
    "<li> Print out results from 'all' SVM kernels for the iris example, and print their predictions for each kernel</li>\n",
    "<li> Add a decisionTree classified to the mix, and print out its prediction with the above 4  SVM kernels</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from six.moves.urllib.request import urlopen\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "label_name = 'Species'\n",
    "\n",
    "def iris_classifier_svm(kernel='rbf',\n",
    "                    model_dir=\"/tmp/iris_model\",\n",
    "                    delete_old_model=False\n",
    "                   ):\n",
    "  \n",
    "  # 0 represents setosa 1 represents versicolor 2 represents virginica\n",
    "  iris_classes = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "  all_kernels=['linear', 'poly', 'rbf', 'sigmoid']  \n",
    "  # If the training and test sets aren't stored locally, download them.\n",
    "  if not os.path.exists(IRIS_TRAINING):\n",
    "    raw = urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if not os.path.exists(IRIS_TEST):\n",
    "    raw = urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"wb\") as f:\n",
    "      f.write(raw)\n",
    "\n",
    "  if delete_old_model:\n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "        print(\"Deleting old model {0}\\n\" .format(model_dir))\n",
    "  # Load datasets.\n",
    "  # Parse the local CSV file.\n",
    "  training_df = pd.read_csv(filepath_or_buffer=IRIS_TRAINING,\n",
    "                                names=CSV_COLUMN_NAMES,  # list of column names\n",
    "                                header=0  # ignore the first row of the CSV file.\n",
    "                               )\n",
    "    # train now holds a pandas DataFrame, which is data structure\n",
    "    # analogous to a table.\n",
    "\n",
    "    # 1. Assign the DataFrame's labels (the right-most column) to train_label.\n",
    "    # 2. Delete (pop) the labels from the DataFrame.\n",
    "    # 3. Assign the remainder of the DataFrame to train_features\n",
    "  train_features, train_label = training_df, training_df.pop(label_name)\n",
    "\n",
    "  \n",
    "  # Apply the preceding logic to the test set.\n",
    "  \n",
    "  test_df = pd.read_csv(IRIS_TEST, names=CSV_COLUMN_NAMES, header=0)\n",
    "  test_features, test_label = test_df, test_df.pop(label_name)\n",
    "\n",
    "\n",
    "  result={}\n",
    "\n",
    "  # Build SVM\n",
    "  if kernel=='all':\n",
    "    for k in range(len(all_kernels)):\n",
    "        kernel=all_kernels[k]\n",
    "        # Set the model type to be SVM-{kernel}\n",
    "        modelType = \"SVM-\" + kernel\n",
    "        print(\"Building SVM using a {0} Kernel\\n\" .format(kernel))\n",
    "\n",
    "        classifier = svm.SVC(decision_function_shape='ovo',kernel=kernel,  probability=True)\n",
    "        # Train model.\n",
    "        classifier.fit(train_features.values, train_label.values)\n",
    "          \n",
    "        # Evaluate accuracy.\n",
    "        accuracy_score_train = classifier.score(train_features.values, train_label.values)\n",
    "        print(\"Train Accuracy: {0:f}\".format(accuracy_score_train))\n",
    "        \n",
    "        # Test model\n",
    "        pred_labels = classifier.predict(test_features.values)\n",
    "        accuracy_score_test = accuracy_score(test_label, pred_labels)\n",
    "        print(\"Test Accuracy: {0:f}\".format(accuracy_score_test))\n",
    "        \n",
    "        print(\"F1 score: {0:f}\\n\".format(f1_score(test_label, pred_labels, average='weighted')))\n",
    "        \n",
    "        \n",
    "        # Classify two new flower samples.\n",
    "        # Classify two new flower samples.\n",
    "        new_samples = np.array(\n",
    "          [[6.4, 3.2, 4.5, 1.5],\n",
    "           [5.8, 3.1, 5.0, 1.7],\n",
    "           [6.4 ,2.8, 5.6 ,2.2],\n",
    "           [5.0 , 2.3 ,3.3 ,1.0 ],\n",
    "           [4.9 ,2.5 ,4.5 ,1.7 ],\n",
    "           [4.9 ,3.1 ,1.5 ,0.1 ],\n",
    "           [5.7,3.8 ,1.7 ,0.3]], dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "        predicted_classes = classifier.predict(new_samples)\n",
    "        probabilities = classifier.predict_log_proba(new_samples)\n",
    "        predicted_class_names = []\n",
    "        for i in range(len(predicted_classes)):\n",
    "            predicted_class_names.append(iris_classes[int(predicted_classes[i])])\n",
    "\n",
    "        #for i in range(len(predicted_classes)):\n",
    "        #  predicted_classes[i] = int(predicted_classes[i])\n",
    "        print(\n",
    "          \"New Samples, Class Predictions:    {}\"\n",
    "          .format(predicted_classes))\n",
    "        print(\n",
    "          \"New Samples, Class Prediction Names:    {}\\n\"\n",
    "          .format(predicted_class_names))\n",
    "        print(\"----x----\")\n",
    "        result[all_kernels[k]]= {\"training-size\" :  train_features.shape,\n",
    "               \"test-size\" : test_features.shape,\n",
    "               \"Model-type\" : modelType,\n",
    "               \"model_dir\"  : model_dir,\n",
    "               \"accuracy\" : accuracy_score_test, \n",
    "               \"prediction\": predicted_classes,\n",
    "               \"prediction-names\": predicted_class_names}\n",
    "\n",
    "        \n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building SVM using a linear Kernel\n",
      "\n",
      "Train Accuracy: 0.983333\n",
      "Test Accuracy: 0.966667\n",
      "F1 score: 0.967030\n",
      "\n",
      "New Samples, Class Predictions:    [1 2 2 1 2 0 0]\n",
      "New Samples, Class Prediction Names:    ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']\n",
      "\n",
      "----x----\n",
      "Building SVM using a poly Kernel\n",
      "\n",
      "Train Accuracy: 0.991667\n",
      "Test Accuracy: 0.966667\n",
      "F1 score: 0.966130\n",
      "\n",
      "New Samples, Class Predictions:    [1 1 2 1 2 0 0]\n",
      "New Samples, Class Prediction Names:    ['versicolor', 'versicolor', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']\n",
      "\n",
      "----x----\n",
      "Building SVM using a rbf Kernel\n",
      "\n",
      "Train Accuracy: 0.975000\n",
      "Test Accuracy: 1.000000\n",
      "F1 score: 1.000000\n",
      "\n",
      "New Samples, Class Predictions:    [1 2 2 1 2 0 0]\n",
      "New Samples, Class Prediction Names:    ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']\n",
      "\n",
      "----x----\n",
      "Building SVM using a sigmoid Kernel\n",
      "\n",
      "Train Accuracy: 0.033333\n",
      "Test Accuracy: 0.033333\n",
      "F1 score: 0.019048\n",
      "\n",
      "New Samples, Class Predictions:    [0 0 0 2 2 2 0]\n",
      "New Samples, Class Prediction Names:    ['setosa', 'setosa', 'setosa', 'virginica', 'virginica', 'virginica', 'setosa']\n",
      "\n",
      "----x----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'linear': {'Model-type': 'SVM-linear',\n",
       "  'accuracy': 0.96666666666666667,\n",
       "  'model_dir': '/tmp/iris_model',\n",
       "  'prediction': array([1, 2, 2, 1, 2, 0, 0]),\n",
       "  'prediction-names': ['versicolor',\n",
       "   'virginica',\n",
       "   'virginica',\n",
       "   'versicolor',\n",
       "   'virginica',\n",
       "   'setosa',\n",
       "   'setosa'],\n",
       "  'test-size': (30, 4),\n",
       "  'training-size': (120, 4)},\n",
       " 'poly': {'Model-type': 'SVM-poly',\n",
       "  'accuracy': 0.96666666666666667,\n",
       "  'model_dir': '/tmp/iris_model',\n",
       "  'prediction': array([1, 1, 2, 1, 2, 0, 0]),\n",
       "  'prediction-names': ['versicolor',\n",
       "   'versicolor',\n",
       "   'virginica',\n",
       "   'versicolor',\n",
       "   'virginica',\n",
       "   'setosa',\n",
       "   'setosa'],\n",
       "  'test-size': (30, 4),\n",
       "  'training-size': (120, 4)},\n",
       " 'rbf': {'Model-type': 'SVM-rbf',\n",
       "  'accuracy': 1.0,\n",
       "  'model_dir': '/tmp/iris_model',\n",
       "  'prediction': array([1, 2, 2, 1, 2, 0, 0]),\n",
       "  'prediction-names': ['versicolor',\n",
       "   'virginica',\n",
       "   'virginica',\n",
       "   'versicolor',\n",
       "   'virginica',\n",
       "   'setosa',\n",
       "   'setosa'],\n",
       "  'test-size': (30, 4),\n",
       "  'training-size': (120, 4)},\n",
       " 'sigmoid': {'Model-type': 'SVM-sigmoid',\n",
       "  'accuracy': 0.033333333333333333,\n",
       "  'model_dir': '/tmp/iris_model',\n",
       "  'prediction': array([0, 0, 0, 2, 2, 2, 0]),\n",
       "  'prediction-names': ['setosa',\n",
       "   'setosa',\n",
       "   'setosa',\n",
       "   'virginica',\n",
       "   'virginica',\n",
       "   'virginica',\n",
       "   'setosa'],\n",
       "  'test-size': (30, 4),\n",
       "  'training-size': (120, 4)}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class SVM\n",
    "# Other kernels = must be one of ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, \n",
    "kernel = \"all\"   \n",
    "iris_classifier_svm(kernel=kernel)\n",
    "\n",
    "## Modify code above to take in a parameter for kernel='all'\n",
    "## Print predictions from each SVM kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<li> You should get the following predictions:  [1, 2, 2, 1, 2, 0, 0]</li>\n",
    "<li>You should get the follwing predictions: ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']</li>\n",
    "    </ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "* I'm just using a simple loop to try all the kernels and pile the results into a JSON format. This modification doesn't handle cases other than \"all\". Since it was specific to this case and only asked to modify the code to meet the requirement, i did it that way. \n",
    "* **Linear**,**Polynomial** and **RBF** kernels give good results. However this function doesn't allow for tuning hyper parameters for regularization and uses the default values for poly, rbf and sigmoid.\n",
    "* Since the new samples don't have labels, we cannot comment on whether the polynomial kernel is overfitting or giving the right results.\n",
    "* SVM is very sensitive to feature scaling and it doesn't seem like that was done for the training data. \n",
    "* The given code says test accuracy but it is done on the training set. So i took the liberty to evaluate the test accuracies and weighted F1 scores \n",
    "* **RBF** seems to have the best accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "<h2> Creating a Decision Tree classifie and printing all predictions </h2>\n",
    "<ul>\n",
    "<li> Wrote a function called iris_classifier_DT() </li>\n",
    "<li> The function returns a JSON compatible object (dictionary) that contains all the results from each classifier\n",
    "<li> Print the Results object: Predictions from DecisionTree</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "\n",
    "def iris_classifier(maxdepth=2,\n",
    "                    model_dir=\"/tmp/DT/iris_model\",\n",
    "                    delete_old_model=False\n",
    "                       ):\n",
    "    # Set the model type \n",
    "    modelType = \"Decision-Tree-\"+str(maxdepth)\n",
    "    # 0 represents setosa 1 represents versicolor 2 represents virginica\n",
    "    iris_classes = [\"setosa\", \"versicolor\", \"virginica\"]\n",
    "    iris = load_iris()\n",
    "    X_train, X_test = iris.data[:120],iris.data[120:]\n",
    "    y_train,y_test = iris.target[:120],iris.target[120:]\n",
    "#     print(X_train.shape,X_train.shape)\n",
    "#     print(X_test.shape,X_test.shape)\n",
    "    \n",
    "    classifier = DecisionTreeClassifier(max_depth=maxdepth, random_state=42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate accuracy.\n",
    "    accuracy_score_train = classifier.score(X_train, y_train)\n",
    "    print(\"Train Accuracy: {0:f}\".format(accuracy_score_train))\n",
    "\n",
    "    # Test model\n",
    "    pred_labels = classifier.predict(X_test)\n",
    "    accuracy_score_test = accuracy_score(y_test, pred_labels)\n",
    "    print(\"Test Accuracy: {0:f}\".format(accuracy_score_test))\n",
    "\n",
    "    print(\"F1 score: {0:f}\\n\".format(f1_score(y_test, pred_labels, average='weighted')))    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Classify two new flower samples.\n",
    "    # Classify two new flower samples.\n",
    "    new_samples = np.array(\n",
    "      [[6.4, 3.2, 4.5, 1.5],\n",
    "       [5.8, 3.1, 5.0, 1.7],\n",
    "       [6.4 ,2.8, 5.6 ,2.2],\n",
    "       [5.0 , 2.3 ,3.3 ,1.0 ],\n",
    "       [4.9 ,2.5 ,4.5 ,1.7 ],\n",
    "       [4.9 ,3.1 ,1.5 ,0.1 ],\n",
    "       [5.7,3.8 ,1.7 ,0.3]], dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "    predicted_classes = classifier.predict(new_samples)\n",
    "    probabilities = classifier.predict_log_proba(new_samples)\n",
    "    predicted_class_names = []\n",
    "    for i in range(len(predicted_classes)):\n",
    "        predicted_class_names.append(iris_classes[int(predicted_classes[i])])\n",
    "\n",
    "    #for i in range(len(predicted_classes)):\n",
    "    #  predicted_classes[i] = int(predicted_classes[i])\n",
    "    print(\n",
    "      \"New Samples, Class Predictions:    {}\"\n",
    "      .format(predicted_classes))\n",
    "    print(\n",
    "      \"New Samples, Class Prediction Names:    {}\\n\"\n",
    "      .format(predicted_class_names))\n",
    "    print(\"----x----\")\n",
    "    \n",
    "    result= {\"training-size\" :  X_train.shape,\n",
    "               \"test-size\" : X_test.shape,\n",
    "               \"max_depth\" : maxdepth,\n",
    "               \"Model-type\" : modelType,\n",
    "               \"model_dir\"  : model_dir,\n",
    "               \"accuracy\" : accuracy_score_test, \n",
    "               \"prediction\": predicted_classes,\n",
    "               \"prediction-names\": predicted_class_names}\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.975000\n",
      "Test Accuracy: 0.833333\n",
      "F1 score: 0.909091\n",
      "\n",
      "New Samples, Class Predictions:    [1 2 2 1 1 0 0]\n",
      "New Samples, Class Prediction Names:    ['versicolor', 'virginica', 'virginica', 'versicolor', 'versicolor', 'setosa', 'setosa']\n",
      "\n",
      "----x----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/root/miniconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/tree/tree.py:864: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model-type': 'Decision-Tree-2',\n",
       " 'accuracy': 0.83333333333333337,\n",
       " 'max_depth': 2,\n",
       " 'model_dir': '/tmp/DT/iris_model',\n",
       " 'prediction': array([1, 2, 2, 1, 1, 0, 0]),\n",
       " 'prediction-names': ['versicolor',\n",
       "  'virginica',\n",
       "  'virginica',\n",
       "  'versicolor',\n",
       "  'versicolor',\n",
       "  'setosa',\n",
       "  'setosa'],\n",
       " 'test-size': (30, 4),\n",
       " 'training-size': (120, 4)}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_classifier_DT(maxdepth=2) # 4,5 are overfitting and 3 gives low values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Logo.png\" style=\"height:75px;width:120px;\" align=\"left\">\n",
    "<h2> Combine SVM and DNN iris_classifiers into a single wrapper and print all predictions </h2>\n",
    "<ul>\n",
    "<li> Write a  function called iris_clasifier() that calls <em>iris_classifier_svm(kernel=\"all\")<em> and <em>iris_classifier_dnn(..)</em></li>\n",
    "<li> The function should return a JSON compaitable object (dictionary) that contains all the results from each classifier\n",
    "<li> Print the Results object: Predictions from all SMV kernels, DecisionTree and DNN </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import collections\n",
    "import os\n",
    "import shutil\n",
    "from six.moves.urllib.request import urlopen\n",
    "#import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
    "                    'PetalLength', 'PetalWidth', 'Species']\n",
    "label_name = 'Species'\n",
    "\n",
    "def iris_classifier(\n",
    "                    model_dir=\"/tmp/final/iris_model\",\n",
    "                    delete_old_model=False\n",
    "                       ): \n",
    "    hidden_units = [10 , 30, 10]\n",
    "    training_steps = 5000\n",
    "    \n",
    "    \n",
    "    result=collections.defaultdict()\n",
    "    result[\"SVM\"]= iris_classifier_svm(kernel='all')\n",
    "    result[\"Decision_Tree\"]=iris_classifier_DT(maxdepth=2)\n",
    "    result[\"DNN\"]= iris_classifier_dnn(hidden_units=hidden_units, \n",
    "                             training_steps=training_steps, \n",
    "                             model_dir=model_dir,\n",
    "                            delete_old_model=delete_old_model)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building SVM using a linear Kernel\n",
      "\n",
      "Train Accuracy: 0.983333\n",
      "Test Accuracy: 0.966667\n",
      "F1 score: 0.967030\n",
      "\n",
      "New Samples, Class Predictions:    [1 2 2 1 2 0 0]\n",
      "New Samples, Class Prediction Names:    ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']\n",
      "\n",
      "----x----\n",
      "Building SVM using a poly Kernel\n",
      "\n",
      "Train Accuracy: 0.991667\n",
      "Test Accuracy: 0.966667\n",
      "F1 score: 0.966130\n",
      "\n",
      "New Samples, Class Predictions:    [1 1 2 1 2 0 0]\n",
      "New Samples, Class Prediction Names:    ['versicolor', 'versicolor', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']\n",
      "\n",
      "----x----\n",
      "Building SVM using a rbf Kernel\n",
      "\n",
      "Train Accuracy: 0.975000\n",
      "Test Accuracy: 1.000000\n",
      "F1 score: 1.000000\n",
      "\n",
      "New Samples, Class Predictions:    [1 2 2 1 2 0 0]\n",
      "New Samples, Class Prediction Names:    ['versicolor', 'virginica', 'virginica', 'versicolor', 'virginica', 'setosa', 'setosa']\n",
      "\n",
      "----x----\n",
      "Building SVM using a sigmoid Kernel\n",
      "\n",
      "Train Accuracy: 0.033333\n",
      "Test Accuracy: 0.033333\n",
      "F1 score: 0.019048\n",
      "\n",
      "New Samples, Class Predictions:    [0 0 0 2 2 2 0]\n",
      "New Samples, Class Prediction Names:    ['setosa', 'setosa', 'setosa', 'virginica', 'virginica', 'virginica', 'setosa']\n",
      "\n",
      "----x----\n",
      "Train Accuracy: 0.975000\n",
      "Test Accuracy: 0.833333\n",
      "F1 score: 0.909091\n",
      "\n",
      "New Samples, Class Predictions:    [1 2 2 1 1 0 0]\n",
      "New Samples, Class Prediction Names:    ['versicolor', 'virginica', 'virginica', 'versicolor', 'versicolor', 'setosa', 'setosa']\n",
      "\n",
      "----x----\n",
      "Deleting old model /tmp/iris_model\n",
      "\n",
      "Featured Columns [_NumericColumn(key='x', shape=(4,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n",
      "\n",
      "Building DNN with [10, 30, 10] hidden units\n",
      "\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_tf_random_seed': 1, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_model_dir': '/tmp/iris_model', '_log_step_count_steps': 100, '_session_config': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/miniconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/root/miniconda3/envs/tfdeeplearning/lib/python3.5/site-packages/sklearn/tree/tree.py:864: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 338.507, step = 1\n",
      "INFO:tensorflow:global_step/sec: 747.292\n",
      "INFO:tensorflow:loss = 14.876, step = 101 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 689.419\n",
      "INFO:tensorflow:loss = 12.2551, step = 201 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.725\n",
      "INFO:tensorflow:loss = 5.85898, step = 301 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 856.951\n",
      "INFO:tensorflow:loss = 16.0844, step = 401 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 786.5\n",
      "INFO:tensorflow:loss = 10.5693, step = 501 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 761.962\n",
      "INFO:tensorflow:loss = 5.93407, step = 601 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 893.7\n",
      "INFO:tensorflow:loss = 5.52508, step = 701 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 855.242\n",
      "INFO:tensorflow:loss = 8.42838, step = 801 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 871.91\n",
      "INFO:tensorflow:loss = 7.99562, step = 901 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 813.304\n",
      "INFO:tensorflow:loss = 6.40393, step = 1001 (0.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 860.61\n",
      "INFO:tensorflow:loss = 4.67692, step = 1101 (0.116 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.184\n",
      "INFO:tensorflow:loss = 5.82164, step = 1201 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 724.026\n",
      "INFO:tensorflow:loss = 5.99711, step = 1301 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 731.13\n",
      "INFO:tensorflow:loss = 4.33366, step = 1401 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 732.117\n",
      "INFO:tensorflow:loss = 2.77807, step = 1501 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 749.663\n",
      "INFO:tensorflow:loss = 10.8097, step = 1601 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 852.903\n",
      "INFO:tensorflow:loss = 9.84758, step = 1701 (0.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 840.734\n",
      "INFO:tensorflow:loss = 6.15685, step = 1801 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.269\n",
      "INFO:tensorflow:loss = 6.93968, step = 1901 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.873\n",
      "INFO:tensorflow:loss = 4.27647, step = 2001 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 823.501\n",
      "INFO:tensorflow:loss = 9.14033, step = 2101 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 847.596\n",
      "INFO:tensorflow:loss = 2.1601, step = 2201 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 745.947\n",
      "INFO:tensorflow:loss = 13.1096, step = 2301 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 745.402\n",
      "INFO:tensorflow:loss = 6.54605, step = 2401 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.093\n",
      "INFO:tensorflow:loss = 3.20381, step = 2501 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 828.148\n",
      "INFO:tensorflow:loss = 5.123, step = 2601 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.558\n",
      "INFO:tensorflow:loss = 4.91935, step = 2701 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 745.438\n",
      "INFO:tensorflow:loss = 7.30279, step = 2801 (0.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.527\n",
      "INFO:tensorflow:loss = 2.49587, step = 2901 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 774.14\n",
      "INFO:tensorflow:loss = 7.35435, step = 3001 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.677\n",
      "INFO:tensorflow:loss = 8.38221, step = 3101 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 780.971\n",
      "INFO:tensorflow:loss = 10.7228, step = 3201 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 708.19\n",
      "INFO:tensorflow:loss = 7.22155, step = 3301 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 889.942\n",
      "INFO:tensorflow:loss = 2.43193, step = 3401 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 900.183\n",
      "INFO:tensorflow:loss = 7.66421, step = 3501 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 899.459\n",
      "INFO:tensorflow:loss = 12.9024, step = 3601 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.076\n",
      "INFO:tensorflow:loss = 3.32706, step = 3701 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 876.307\n",
      "INFO:tensorflow:loss = 4.88017, step = 3801 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 883.233\n",
      "INFO:tensorflow:loss = 6.35973, step = 3901 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 907.088\n",
      "INFO:tensorflow:loss = 6.98093, step = 4001 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 904.938\n",
      "INFO:tensorflow:loss = 7.17768, step = 4101 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 896.385\n",
      "INFO:tensorflow:loss = 2.06425, step = 4201 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 902.671\n",
      "INFO:tensorflow:loss = 4.96481, step = 4301 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 920.076\n",
      "INFO:tensorflow:loss = 3.16777, step = 4401 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 908.456\n",
      "INFO:tensorflow:loss = 4.07287, step = 4501 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 895.455\n",
      "INFO:tensorflow:loss = 5.93486, step = 4601 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 917.072\n",
      "INFO:tensorflow:loss = 2.14544, step = 4701 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 786.105\n",
      "INFO:tensorflow:loss = 2.28405, step = 4801 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 835.74\n",
      "INFO:tensorflow:loss = 2.39963, step = 4901 (0.120 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 9.40149.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-25-13:21:13\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-25-13:21:13\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.966667, average_loss = 0.0635979, global_step = 5000, loss = 1.90794\n",
      "\n",
      "Test Accuracy: 0.966667\n",
      "\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-5000\n",
      "New Samples, Class Predictions:    [1, 2, 2, 1, 2, 0, 0]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'DNN': {'accuracy': 0.96666664,\n",
       "              'hidden-units': '[10, 30, 10]',\n",
       "              'model-type': 'DNN',\n",
       "              'model_dir': '/tmp/iris_model',\n",
       "              'prediction': [1, 2, 2, 1, 2, 0, 0],\n",
       "              'prediction-names': ['versicolor',\n",
       "               'virginica',\n",
       "               'virginica',\n",
       "               'versicolor',\n",
       "               'virginica',\n",
       "               'setosa',\n",
       "               'setosa'],\n",
       "              'probabilities': [99.991989135742188,\n",
       "               74.301350116729736,\n",
       "               99.972003698348999,\n",
       "               99.865061044692993,\n",
       "               99.057114124298096,\n",
       "               99.986529350280762,\n",
       "               99.990260601043701],\n",
       "              'test-size': (30, 4),\n",
       "              'train-steps': 5000,\n",
       "              'training-size': (120, 4)},\n",
       "             'Decision_Tree': {'Model-type': 'Decision-Tree-2',\n",
       "              'accuracy': 0.83333333333333337,\n",
       "              'max_depth': 2,\n",
       "              'model_dir': '/tmp/DT/iris_model',\n",
       "              'prediction': array([1, 2, 2, 1, 1, 0, 0]),\n",
       "              'prediction-names': ['versicolor',\n",
       "               'virginica',\n",
       "               'virginica',\n",
       "               'versicolor',\n",
       "               'versicolor',\n",
       "               'setosa',\n",
       "               'setosa'],\n",
       "              'test-size': (30, 4),\n",
       "              'training-size': (120, 4)},\n",
       "             'SVM': {'linear': {'Model-type': 'SVM-linear',\n",
       "               'accuracy': 0.96666666666666667,\n",
       "               'model_dir': '/tmp/iris_model',\n",
       "               'prediction': array([1, 2, 2, 1, 2, 0, 0]),\n",
       "               'prediction-names': ['versicolor',\n",
       "                'virginica',\n",
       "                'virginica',\n",
       "                'versicolor',\n",
       "                'virginica',\n",
       "                'setosa',\n",
       "                'setosa'],\n",
       "               'test-size': (30, 4),\n",
       "               'training-size': (120, 4)},\n",
       "              'poly': {'Model-type': 'SVM-poly',\n",
       "               'accuracy': 0.96666666666666667,\n",
       "               'model_dir': '/tmp/iris_model',\n",
       "               'prediction': array([1, 1, 2, 1, 2, 0, 0]),\n",
       "               'prediction-names': ['versicolor',\n",
       "                'versicolor',\n",
       "                'virginica',\n",
       "                'versicolor',\n",
       "                'virginica',\n",
       "                'setosa',\n",
       "                'setosa'],\n",
       "               'test-size': (30, 4),\n",
       "               'training-size': (120, 4)},\n",
       "              'rbf': {'Model-type': 'SVM-rbf',\n",
       "               'accuracy': 1.0,\n",
       "               'model_dir': '/tmp/iris_model',\n",
       "               'prediction': array([1, 2, 2, 1, 2, 0, 0]),\n",
       "               'prediction-names': ['versicolor',\n",
       "                'virginica',\n",
       "                'virginica',\n",
       "                'versicolor',\n",
       "                'virginica',\n",
       "                'setosa',\n",
       "                'setosa'],\n",
       "               'test-size': (30, 4),\n",
       "               'training-size': (120, 4)},\n",
       "              'sigmoid': {'Model-type': 'SVM-sigmoid',\n",
       "               'accuracy': 0.033333333333333333,\n",
       "               'model_dir': '/tmp/iris_model',\n",
       "               'prediction': array([0, 0, 0, 2, 2, 2, 0]),\n",
       "               'prediction-names': ['setosa',\n",
       "                'setosa',\n",
       "                'setosa',\n",
       "                'virginica',\n",
       "                'virginica',\n",
       "                'virginica',\n",
       "                'setosa'],\n",
       "               'test-size': (30, 4),\n",
       "               'training-size': (120, 4)}}})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = \"/tmp/iris_model\"\n",
    "delete_old_model= False\n",
    "iris_classifier(model_dir,delete_old_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
